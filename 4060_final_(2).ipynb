{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jsvuC1F3VZtq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9e238bb-36c7-4ebf-97f1-6b6b29089385",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyreadr\n",
            "  Downloading pyreadr-0.5.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.12/dist-packages (3.1.5)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.12/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Downloading pyreadr-0.5.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (776 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/776.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m532.5/776.2 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.2/776.2 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyreadr\n",
            "Successfully installed pyreadr-0.5.4\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.12/dist-packages (4.6.0)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from lightgbm) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from lightgbm) (1.16.3)\n",
            "Collecting lifelines\n",
            "  Downloading lifelines-0.30.0-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from lifelines) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from lifelines) (1.16.3)\n",
            "Requirement already satisfied: pandas>=2.1 in /usr/local/lib/python3.12/dist-packages (from lifelines) (2.2.2)\n",
            "Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.12/dist-packages (from lifelines) (3.10.0)\n",
            "Requirement already satisfied: autograd>=1.5 in /usr/local/lib/python3.12/dist-packages (from lifelines) (1.8.0)\n",
            "Collecting autograd-gamma>=0.3 (from lifelines)\n",
            "  Downloading autograd-gamma-0.5.0.tar.gz (4.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting formulaic>=0.2.2 (from lifelines)\n",
            "  Downloading formulaic-1.2.1-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting interface-meta>=1.2.0 (from formulaic>=0.2.2->lifelines)\n",
            "  Downloading interface_meta-1.3.0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: narwhals>=1.17 in /usr/local/lib/python3.12/dist-packages (from formulaic>=0.2.2->lifelines) (2.12.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.12/dist-packages (from formulaic>=0.2.2->lifelines) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.0 in /usr/local/lib/python3.12/dist-packages (from formulaic>=0.2.2->lifelines) (2.0.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0->lifelines) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0->lifelines) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0->lifelines) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0->lifelines) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0->lifelines) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0->lifelines) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0->lifelines) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0->lifelines) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.1->lifelines) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.1->lifelines) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0->lifelines) (1.17.0)\n",
            "Downloading lifelines-0.30.0-py3-none-any.whl (349 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m349.3/349.3 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading formulaic-1.2.1-py3-none-any.whl (117 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.3/117.3 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading interface_meta-1.3.0-py3-none-any.whl (14 kB)\n",
            "Building wheels for collected packages: autograd-gamma\n",
            "  Building wheel for autograd-gamma (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for autograd-gamma: filename=autograd_gamma-0.5.0-py3-none-any.whl size=4030 sha256=139aa70858d7c245c919d58ba9630fd97ea903c3b40fc4065d1a2f040ae21c04\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/37/21/0a719b9d89c635e89ff24bd93b862882ad675279552013b2fb\n",
            "Successfully built autograd-gamma\n",
            "Installing collected packages: interface-meta, autograd-gamma, formulaic, lifelines\n",
            "Successfully installed autograd-gamma-0.5.0 formulaic-1.2.1 interface-meta-1.3.0 lifelines-0.30.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyreadr pandas openpyxl\n",
        "!pip install --upgrade lightgbm\n",
        "!pip install lifelines"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Data Preparation***"
      ],
      "metadata": {
        "id": "Xpr1_-ClqPn6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**step1**"
      ],
      "metadata": {
        "id": "9w6LHWCN2qKk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pyreadr\n",
        "import pandas as pd\n",
        "\n",
        "in_path = \"/content/IMvigor210CoreBiologies.Rdata\"\n",
        "out_prefix = \"/content/IMvigor210_data\"\n",
        "\n",
        "result = pyreadr.read_r(in_path)\n",
        "\n",
        "with pd.ExcelWriter(f\"{out_prefix}.xlsx\") as xw:\n",
        "    for name, df in result.items():\n",
        "        csv_path = f\"{out_prefix}_{name}.csv\"\n",
        "        df.to_csv(csv_path, index=False)\n",
        "\n",
        "        sheet = name[:31]\n",
        "        df.to_excel(xw, sheet_name=sheet, index=False)"
      ],
      "metadata": {
        "id": "ebcUYPkLr4X2",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "outputId": "75c23f6b-0134-4a40-8d7a-8792dcb01057"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "PyreadrError",
          "evalue": "File b'/content/IMvigor210CoreBiologies.Rdata' does not exist!",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPyreadrError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2396150701.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mout_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/IMvigor210_data\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyreadr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_r\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExcelWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{out_prefix}.xlsx\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mxw\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyreadr/pyreadr.py\u001b[0m in \u001b[0;36mread_r\u001b[0;34m(path, use_objects, timezone)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mfilename_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mPyreadrError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File {0} does not exist!\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mPyreadrError\u001b[0m: File b'/content/IMvigor210CoreBiologies.Rdata' does not exist!"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#sampleID 修复\n",
        "import pandas as pd\n",
        "\n",
        "anno = pd.read_csv(\"/content/IMvigor210_data_annoData.csv\")\n",
        "expr = pd.read_csv(\"/content/IMvigor210_data_expreSet.csv\")\n",
        "pheno = pd.read_csv(\"/content/IMvigor210_data_phenoData.csv\")\n",
        "\n",
        "sample_ids = list(expr.columns)\n",
        "\n",
        "pheno.insert(0, \"SampleID\", sample_ids)\n",
        "\n",
        "expr_T = expr.T.copy()\n",
        "expr_T.index.name = \"SampleID\"\n",
        "expr_T.reset_index(inplace=True)\n",
        "\n",
        "pheno.to_csv(\"IMvigor210_pheno_fixed.csv\", index=False)\n",
        "expr_T.to_csv(\"IMvigor210_expr_fixed.csv\", index=False)"
      ],
      "metadata": {
        "id": "-VxNYy0uHkaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\npheno_fixed columns:\", pheno_fixed.columns.tolist()[:20])\n",
        "print(\"\\nexpr_fixed columns:\", expr_fixed.columns.tolist()[:20])\n"
      ],
      "metadata": {
        "id": "M5r8y5_j8XcJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "step2"
      ],
      "metadata": {
        "id": "eTbwwnSd2t36"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "pheno_path = \"/content/IMvigor210_pheno_fixed.csv\"\n",
        "pheno = pd.read_csv(pheno_path)\n",
        "\n",
        "col_map = {\n",
        "    \"Age\":        \"Sample age\",\n",
        "    \"ECOG\":       \"Baseline ECOG Score\",\n",
        "    \"PDL1_IC\":    \"IC Level\",\n",
        "    \"PDL1_TC\":    \"TC Level\",\n",
        "    \"TMB\":        \"FMOne mutation burden per MB\",\n",
        "    \"Smoking\":    \"Tobacco Use History\",\n",
        "    \"time\":       \"os\",\n",
        "    \"censOS\":     \"censOS\"\n",
        "}\n",
        "\n",
        "\n",
        "keep_cols = [\"SampleID\"] + [v for v in col_map.values() if v in pheno.columns]\n",
        "clin = pheno[keep_cols].copy()\n",
        "\n",
        "rename_dict = {v: k for k, v in col_map.items() if v in clin.columns}\n",
        "clin.rename(columns=rename_dict, inplace=True)\n",
        "\n",
        "for c in [\"Age\", \"ECOG\", \"TMB\"]:\n",
        "    if c in clin.columns:\n",
        "        clin[c] = pd.to_numeric(clin[c], errors=\"coerce\")\n",
        "\n",
        "for c in [\"Age\", \"ECOG\", \"TMB\"]:\n",
        "    if c in clin.columns:\n",
        "        mean = clin[c].mean(skipna=True)\n",
        "        std  = clin[c].std(skipna=True)\n",
        "        clin[c + \"_z\"] = (clin[c] - mean) / std\n",
        "\n",
        "# 构建生存标签\n",
        "if \"time\" in clin.columns and \"censOS\" in clin.columns:\n",
        "    clin[\"censOS\"] = pd.to_numeric(clin[\"censOS\"], errors=\"coerce\").fillna(1).astype(int)\n",
        "    clin[\"event\"] = 1 - clin[\"censOS\"]\n",
        "else:\n",
        "    raise ValueError(\"缺少 'os' 或 'censOS' 列，请检查 phenoData。\")\n",
        "\n",
        "# 类别变量清洗 One-Hot 编码\n",
        "cat_cols = []\n",
        "for c in [\"PDL1_IC\", \"PDL1_TC\", \"Smoking\"]:\n",
        "    if c in clin.columns:\n",
        "        cat_cols.append(c)\n",
        "        clin[c] = clin[c].astype(str).str.strip().replace({\"nan\": np.nan})\n",
        "\n",
        "clin_encoded = pd.get_dummies(clin, columns=cat_cols, drop_first=False, dummy_na=False)\n",
        "\n",
        "\n",
        "out_path = \"IMvigor210_clinical_step2_processed.csv\"\n",
        "clin_encoded.to_csv(out_path, index=False, encoding=\"utf-8\")\n",
        "\n",
        "print(\"样本数 × 特征数：\", clin_encoded.shape)"
      ],
      "metadata": {
        "id": "phQjF6DjxGo1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "step3"
      ],
      "metadata": {
        "id": "mW369jwa6Lyq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "expre_csv = \"/content/IMvigor210_expr_fixed.csv\"\n",
        "\n",
        "\n",
        "TPM_MIN = 1.0\n",
        "FRACTION_MIN = 0.10\n",
        "TOP_K = 1000\n",
        "\n",
        "expr = pd.read_csv(expre_csv, index_col=0)\n",
        "expr = expr.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# log1p 变换\n",
        "expr_log1p = np.log1p(expr)\n",
        "\n",
        "# 低表达过滤\n",
        "mask_keep = (expr > TPM_MIN).sum(axis=1) >= max(1, int(FRACTION_MIN * expr.shape[1]))\n",
        "expr_filtered = expr_log1p.loc[mask_keep]\n",
        "\n",
        "# 按方差排序\n",
        "vars_ = expr_filtered.var(axis=1).sort_values(ascending=False)\n",
        "keep_top = vars_.head(min(TOP_K, expr_filtered.shape[0])).index\n",
        "\n",
        "expr_top1000 = expr_filtered.loc[keep_top]\n",
        "\n",
        "out_path = \"rnaseq_top1000_by_variance.csv\"\n",
        "expr_top1000.to_csv(out_path)\n",
        "print(\"最终 top-1000:\", expr_top1000.shape)"
      ],
      "metadata": {
        "id": "r6snHio16Pbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "step4"
      ],
      "metadata": {
        "id": "fTvU7is1Wf8Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "clinical_path = \"/content/IMvigor210_clinical_step2_processed.csv\"  # Step 2 输出\n",
        "rnaseq_path   = \"/content/rnaseq_top1000_by_variance.csv\"  # Step 3 输出\n",
        "\n",
        "clinical = pd.read_csv(clinical_path)\n",
        "\n",
        "# 统一成字符串\n",
        "clinical[\"SampleID\"] = clinical[\"SampleID\"].astype(str).str.strip()\n",
        "\n",
        "rnaseq = pd.read_csv(rnaseq_path)\n",
        "\n",
        "rnaseq[\"SampleID\"] = rnaseq[\"SampleID\"].astype(str).str.strip()\n",
        "rnaseq = rnaseq.set_index(\"SampleID\")\n",
        "\n",
        "\n",
        "rna_ids  = rnaseq.index.astype(str)\n",
        "clin_ids = clinical[\"SampleID\"].astype(str)\n",
        "\n",
        "common_ids = sorted(set(rna_ids).intersection(set(clin_ids)))\n",
        "\n",
        "\n",
        "# 按照 common_ids 的顺序重新排列，保证两个表一一对应\n",
        "clinical_sub = (\n",
        "    clinical\n",
        "    .set_index(\"SampleID\")\n",
        "    .loc[common_ids]\n",
        ")\n",
        "rnaseq_sub = rnaseq.loc[common_ids]\n",
        "\n",
        "\n",
        "y_time  = clinical_sub[\"time\"].astype(float).values\n",
        "y_event = clinical_sub[\"event\"].astype(int).values\n",
        "\n",
        "# 构建最终特征矩阵 X\n",
        "drop_cols = [c for c in [\"time\", \"event\", \"censOS\"] if c in clinical_sub.columns]\n",
        "clinical_features = clinical_sub.drop(columns=drop_cols)\n",
        "\n",
        "X = pd.concat([clinical_features, rnaseq_sub], axis=1)\n",
        "\n",
        "print(f\"整合后样本数: {X.shape[0]}, 特征数: {X.shape[1]}\")\n",
        "\n",
        "# 保存整合后的特征和标签（保存在当前目录）\n",
        "features_out = \"IMvigor210_features_step4.csv\"\n",
        "labels_out   = \"IMvigor210_labels_step4.csv\"\n",
        "\n",
        "X.to_csv(features_out)\n",
        "pd.DataFrame({\n",
        "    \"SampleID\": common_ids,\n",
        "    \"time\": y_time,\n",
        "    \"event\": y_event\n",
        "}).to_csv(labels_out, index=False)\n",
        "\n",
        "print(f\"已保存整合特征到: {features_out}\")\n",
        "print(f\"已保存标签到    : {labels_out}\")\n",
        "\n",
        "# 5 折交叉验证划分（patient-level）\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "skf = StratifiedKFold(\n",
        "    n_splits=5,\n",
        "    shuffle=True,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "fold_assign = pd.DataFrame({\n",
        "    \"SampleID\": common_ids,\n",
        "    \"fold\": -1\n",
        "})\n",
        "\n",
        "for fold_id, (_, val_idx) in enumerate(skf.split(X.values, y_event), start=1):\n",
        "    val_ids = [common_ids[i] for i in val_idx]\n",
        "    fold_assign.loc[fold_assign[\"SampleID\"].isin(val_ids), \"fold\"] = fold_id\n",
        "\n",
        "\n",
        "folds_out = \"IMvigor210_cv5_folds_step4.csv\"\n",
        "fold_assign.to_csv(folds_out, index=False)\n",
        "\n",
        "print(f\"已保存 5 折划分到: {folds_out}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "N6SiDGYfnQ7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 读入 step4 输出\n",
        "X = pd.read_csv(\"IMvigor210_features_step4.csv\", index_col=0)\n",
        "labels = pd.read_csv(\"IMvigor210_labels_step4.csv\")\n",
        "time_os = labels[\"time\"].values\n",
        "event = labels[\"event\"].values\n",
        "\n",
        "# 假设前面几列是临床，后面是 RNA（你可以根据列名切）\n",
        "clin_cols = [c for c in X.columns if c.startswith(\"Age\") or c.startswith(\"ECOG\") or \"PDL1\" in c or \"Smoking\" in c or \"TMB\" in c]\n",
        "rna_cols  = [c for c in X.columns if c not in clin_cols]\n",
        "\n",
        "X_clin = X[clin_cols]\n",
        "X_rna  = X[rna_cols]\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_rna_scaled = scaler.fit_transform(X_rna)\n",
        "\n",
        "pca = PCA(n_components=70)\n",
        "X_rna_pca = pca.fit_transform(X_rna_scaled)\n",
        "\n",
        "X_pca = pd.concat(\n",
        "    [X_clin.reset_index(drop=True),\n",
        "     pd.DataFrame(X_rna_pca, columns=[f\"PC{i+1}\" for i in range(X_rna_pca.shape[1])])],\n",
        "    axis=1\n",
        ")\n",
        "X_pca.to_csv(\"IMvigor210_features_step4_PCA50.csv\")"
      ],
      "metadata": {
        "id": "14Qizni3asTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "step5"
      ],
      "metadata": {
        "id": "bFCpjfZB2BY1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "\n",
        "# 读取 Step4 输出\n",
        "X = pd.read_csv(\"IMvigor210_features_step4_PCA50.csv\", index_col=0)\n",
        "labels = pd.read_csv(\"IMvigor210_labels_step4.csv\")\n",
        "folds = pd.read_csv(\"IMvigor210_cv5_folds_step4.csv\")\n",
        "\n",
        "ids = labels[\"SampleID\"].tolist()\n",
        "time_os = labels[\"time\"].values\n",
        "event = labels[\"event\"].values\n",
        "\n",
        "y = np.log(time_os + 1e-6)\n",
        "\n",
        "print(f\"样本数: {X.shape[0]}, 特征数: {X.shape[1]}\")\n",
        "\n",
        "# 超参数：中等网格（9 组）\n",
        "num_leaves_list = [31, 63, 127]\n",
        "learning_rate_list = [0.01, 0.03, 0.05]\n",
        "\n",
        "medium_param_list = []\n",
        "\n",
        "for nl in num_leaves_list:\n",
        "    for lr in learning_rate_list:\n",
        "        medium_param_list.append({\n",
        "            \"num_leaves\": nl,\n",
        "            \"learning_rate\": lr,\n",
        "            \"min_data_in_leaf\": 20,\n",
        "            \"max_depth\": -1,\n",
        "            \"lambda_l1\": 0.0,\n",
        "            \"lambda_l2\": 0.1,\n",
        "            \"subsample\": 0.8,\n",
        "            \"colsample_bytree\": 0.8,\n",
        "            \"n_estimators\": 1000,\n",
        "        })\n",
        "\n",
        "print(\"超参组合数量：\", len(medium_param_list))  # 应为 9\n",
        "\n",
        "# 5-fold CV 训练（计时）\n",
        "oof_pred = np.zeros(len(X))\n",
        "model_records = []\n",
        "\n",
        "global_start = time.time()\n",
        "\n",
        "for fold in range(1, 6):\n",
        "\n",
        "    fold_start = time.time()\n",
        "\n",
        "    val_mask = folds[\"fold\"] == fold\n",
        "    train_mask = ~val_mask\n",
        "\n",
        "    train_idx = folds.index[train_mask]\n",
        "    val_idx   = folds.index[val_mask]\n",
        "\n",
        "    X_train = X.iloc[train_idx]\n",
        "    X_val   = X.iloc[val_idx]\n",
        "\n",
        "    y_train = y[train_idx]\n",
        "    y_val   = y[val_idx]\n",
        "\n",
        "    train_set = lgb.Dataset(X_train, label=y_train)\n",
        "    val_set   = lgb.Dataset(X_val, label=y_val)\n",
        "\n",
        "    best_rmse = np.inf\n",
        "    best_model = None\n",
        "    best_param = None\n",
        "\n",
        "    # 超参搜索（9 组合）\n",
        "    for params in medium_param_list:\n",
        "        p = params.copy()\n",
        "        p.update({\n",
        "            \"objective\": \"regression\",\n",
        "            \"metric\": \"rmse\",\n",
        "            \"verbosity\": -1,\n",
        "            \"num_threads\": 4,\n",
        "        })\n",
        "\n",
        "        model = lgb.train(\n",
        "            p,\n",
        "            train_set,\n",
        "            valid_sets=[val_set],\n",
        "            num_boost_round=5000,\n",
        "            callbacks=[\n",
        "                lgb.early_stopping(stopping_rounds=200, verbose=False)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        rmse = model.best_score[\"valid_0\"][\"rmse\"]\n",
        "\n",
        "        if rmse < best_rmse:\n",
        "            best_rmse = rmse\n",
        "            best_model = model\n",
        "            best_param = p\n",
        "\n",
        "    fold_time = time.time() - fold_start\n",
        "    print(f\"Fold {fold} 最佳 RMSE = {best_rmse:.4f}, 用时 {fold_time:.1f} 秒\")\n",
        "\n",
        "    model_records.append(best_param)\n",
        "    oof_pred[val_idx] = best_model.predict(X_val, num_iteration=best_model.best_iteration)\n",
        "\n",
        "\n",
        "# Derived Risk Score = -pred\n",
        "risk_score = -oof_pred\n",
        "\n",
        "out_df = pd.DataFrame({\n",
        "    \"SampleID\": ids,\n",
        "    \"predicted_log_survival\": oof_pred,\n",
        "    \"risk_score\": risk_score,\n",
        "})\n",
        "out_df.to_csv(\"IMvigor210_step5_lightgbm_medium_regression_predictions.csv\",\n",
        "              index=False)\n",
        "\n",
        "pd.DataFrame(model_records).to_csv(\n",
        "    \"IMvigor210_step5_medium_best_params_regression.csv\",\n",
        "    index=False\n",
        ")"
      ],
      "metadata": {
        "id": "ZexzMaMo0mf7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "step6"
      ],
      "metadata": {
        "id": "ghHmFKyY2GPt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6 – Evaluation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from lifelines import KaplanMeierFitter\n",
        "from lifelines.statistics import logrank_test\n",
        "from lifelines.utils import concordance_index\n",
        "\n",
        "pred = pd.read_csv(\"IMvigor210_step5_lightgbm_medium_regression_predictions.csv\")\n",
        "labels = pd.read_csv(\"IMvigor210_labels_step4.csv\")\n",
        "\n",
        "df = pred.merge(labels, on=\"SampleID\")\n",
        "\n",
        "risk = df[\"risk_score\"].values\n",
        "time_os = df[\"time\"].values\n",
        "event = df[\"event\"].values\n",
        "\n",
        "print(\"数据量：\", len(df))\n",
        "\n",
        "\n",
        "cindex = concordance_index(time_os, -risk, event)\n",
        "\n",
        "\n",
        "print(f\"C-index = {cindex:.4f}\")\n",
        "\n",
        "with open(\"IMvigor210_step6_Cindex.txt\", \"w\") as f:\n",
        "    f.write(f\"C-index = {cindex:.4f}\")\n",
        "\n",
        "\n",
        "# 按风险中位数分 high-risk / low-risk\n",
        "median_risk = np.median(risk)\n",
        "group = (risk >= median_risk).astype(int)\n",
        "\n",
        "df[\"risk_group\"] = group\n",
        "\n",
        "kmf = KaplanMeierFitter()\n",
        "\n",
        "plt.figure(figsize=(7,5))\n",
        "\n",
        "# Low risk group\n",
        "kmf.fit(\n",
        "    durations=df[group==0][\"time\"],\n",
        "    event_observed=df[group==0][\"event\"],\n",
        "    label=\"Low Risk\"\n",
        ")\n",
        "kmf.plot(ci_show= False)\n",
        "\n",
        "# High risk group\n",
        "kmf.fit(\n",
        "    durations=df[group==1][\"time\"],\n",
        "    event_observed=df[group==1][\"event\"],\n",
        "    label=\"High Risk\"\n",
        ")\n",
        "kmf.plot(ci_show= False)\n",
        "\n",
        "plt.title(\"Kaplan–Meier Curve by Predicted Risk Groups\")\n",
        "plt.xlabel(\"Time (days)\")\n",
        "plt.ylabel(\"Survival Probability\")\n",
        "plt.grid(alpha=0.3)\n",
        "\n",
        "plt.savefig(\"IMvigor210_step6_KM_curve.png\", dpi=300)\n",
        "plt.show()\n",
        "\n",
        "# ------- log-rank test -------\n",
        "results = logrank_test(\n",
        "    df[group==0][\"time\"],\n",
        "    df[group==1][\"time\"],\n",
        "    df[group==0][\"event\"],\n",
        "    df[group==1][\"event\"]\n",
        ")\n",
        "\n",
        "print(f\"p-value = {results.p_value:.4e}\")\n",
        "\n",
        "with open(\"IMvigor210_step6_logrank_p.txt\", \"w\") as f:\n",
        "    f.write(f\"log-rank p-value = {results.p_value:.4e}\")"
      ],
      "metadata": {
        "id": "whCyBPiQ0nt2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Survival Time Distribution & Event Counts"
      ],
      "metadata": {
        "id": "j31DmdnDQZry"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "labels = pd.read_csv(\"IMvigor210_labels_step4.csv\")\n",
        "\n",
        "plt.figure(figsize=(7,5), dpi=150)\n",
        "plt.hist(labels[\"time\"], bins=30, edgecolor=\"black\", alpha=0.8)\n",
        "plt.xlabel(\"Overall survival time (months)\", fontsize=12)\n",
        "plt.ylabel(\"Number of patients\", fontsize=12)\n",
        "plt.title(\"Distribution of survival times\", fontsize=14)\n",
        "plt.tick_params(axis=\"both\", labelsize=11)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(5,5), dpi=150)\n",
        "labels[\"event\"].value_counts().sort_index().plot(kind=\"bar\", edgecolor=\"black\")\n",
        "plt.xticks([0,1], [\"Censored (0)\", \"Death (1)\"], rotation=0, fontsize=11)\n",
        "plt.ylabel(\"Number of patients\", fontsize=12)\n",
        "plt.title(\"Event vs censored\", fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "kzERUUc2Qd5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Risk Score Distribution"
      ],
      "metadata": {
        "id": "zNLZ7erVKSKD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pred = pd.read_csv(\"IMvigor210_step5_lightgbm_medium_regression_predictions.csv\")\n",
        "labels = pd.read_csv(\"IMvigor210_labels_step4.csv\")\n",
        "df = pred.merge(labels, on=\"SampleID\")\n",
        "\n",
        "plt.figure(figsize=(7,5), dpi=150)\n",
        "plt.hist(df[\"risk_score\"], bins=30, edgecolor=\"black\", alpha=0.8)\n",
        "plt.xlabel(\"Risk score\", fontsize=12)\n",
        "plt.ylabel(\"Number of patients\", fontsize=12)\n",
        "plt.title(\"Risk score distribution\", fontsize=14)\n",
        "plt.tick_params(axis=\"both\", labelsize=11)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(7,5), dpi=150)\n",
        "df.boxplot(column=\"risk_score\", by=\"event\")\n",
        "plt.xticks([1,2], [\"Censored (0)\", \"Death (1)\"], fontsize=11)\n",
        "plt.xlabel(\"Event\", fontsize=12)\n",
        "plt.ylabel(\"Risk score\", fontsize=12)\n",
        "plt.title(\"Risk score distribution by event\", fontsize=14)\n",
        "plt.suptitle(\"\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rYAdoMp5KWmK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}